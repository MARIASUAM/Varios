---
title: "Diario_calibracion_validacion"
output: html_document
---

```{r}
# Definir directorio: si se abre desde "Project" es necesario abrirlo desde el menú (Session>Set working directory>...)
setwd("C:/DELL/GDrive_2/Instar/calibracion_validacion/fuentes_datos_validacion/COPLAS_PLAGAS/")
```

## Datos INSTAR crudos:
   
```{r}
# Datos crudos de INSTAR_SN:
huevos <-read.table("huevos_sn.csv", header=T, sep=",", dec=".")
L1 <-read.table("L1_sn.csv", header=T, sep=",", dec=".")
L2 <-read.table("L2_sn.csv", header=T, sep=",", dec=".")
crisalidas <-read.table("crisalidas_sn.csv", header=T, sep=",", dec=".")
exergia <-read.table("vigor_sn.csv", header=T, sep=",", dec=".")

# Juntamos todos en una misma tabla

INSTAR_SN <- cbind(huevos, L1$L1, L2$L2, crisalidas$crisalida, exergia$exergia)
names(INSTAR_SN)[1] <- "fecha"
names(INSTAR_SN)[3] <- "l1"
names(INSTAR_SN)[4] <- "l2"
names(INSTAR_SN)[5] <- "crisalidas"
names(INSTAR_SN)[6] <- "exergia"

# Crear columna anio
INSTAR_SN$fecha <-as.Date(INSTAR_SN$fecha, format="%d-%m-%y")
INSTAR_SN$anio<-as.numeric(format(INSTAR_SN$fecha, "%Y"))
```

**Importante**: recordar que mientras huevos, l1, l2 y crisalidas son valores absolutos (numero total de individuos en el mundo Netlogo), exergia es la media del vigor de todos los hospedadores del mundo NetLogo.

En nuestros datos hay solapamiento de fases no consecutivas (cosa que, en principio, no debería ocurrir).

# Agregacion de datos INSTAR: 

En cualquier caso, *la agregación no se debería hacer por año natural, sino por ciclo biológico!*
¿cuándo es la medicion de COPLAS? contar años asi --> POR HACER

Entiendo que agregais los datos de NetLogo para poder hacer la regreson COPLAS vs INSTAR, es correcto? ~~Sin embargo, sumar los datos de huevos, l1, l2 y crisalidas de todos los dias no parece adecuado, asi habra individuos que se cuentan dos veces no? Entiendo que es dificil encontrar el parametro adecuado, ya que no sabemos que huevos hoy son los mismos que maniana y cuales son nuevos...~~

Antonio me comenta que ahi podria entrar un analisis de dinamica poblacional. Ya que la cosa se complica bastante, quizas para simplificar se podria probar con la media, el maximo y/o el minimo, que quizas sean valores mas reales que el acumulado que se ha usado hasta ahora. ~~De hecho, "Resultados_agreg_Instar_SN.csv" tiene mas individuos en L2 que en L1, lo cual no tiene sentido...No?~~ (Ver razonamiento en "Agregacion por suma")

## Agregacion por suma
La suma de los individuos de cada instar para un mismo anio es una forma de calcular los "dias equivalentes del instar". Asi, sumando todos los l1 de un anio no obtenemos numero total de l1 sino dias equivalentes de afeccion de l1. Por tanto, la suma tiene sentido para "huevos", "l1", "l2" y "crisalidas", no para "exergia":

```{r}
sum_huevos <- aggregate(x = INSTAR_SN$huevos, by=list(anio=INSTAR_SN$anio), FUN=sum, na.rm=TRUE)
names(sum_huevos)[2] <- "sum_huevos"
sum_l1<- aggregate(x = INSTAR_SN$l1, by=list(anio=INSTAR_SN$anio), FUN=sum, na.rm=TRUE)
names(sum_l1)[2] <- "sum_l1"
sum_l2<- aggregate(x = INSTAR_SN$l2, by=list(anio=INSTAR_SN$anio), FUN=sum, na.rm=TRUE)
names(sum_l2)[2] <- "sum_l2"
sum_crisalidas<- aggregate(x = INSTAR_SN$crisalidas, by=list(anio=INSTAR_SN$anio), FUN=sum, na.rm=TRUE)
names(sum_crisalidas)[2] <- "sum_crisalidas"

sum_INSTAR<- cbind(sum_huevos,sum_l1, sum_l2, sum_crisalidas)
sum_INSTAR <- sum_INSTAR[ -c(3,5,7) ]
```

## Agregacion por maximo
Dos anios con el mismo numero de individuos pueden tener maximos muy diferentes, segun la puesta, eclosion, etc coincida mas o menos en el tiempo (mismo efecto que la media). El valor maximo, por tanto, debe ser usado con precaución, aunque si puede ser una manera de estimar (solo estimar!) el numero total de individuos que se han dado en un anio para un instar.

```{r}
max_huevos <- aggregate(x = INSTAR_SN$huevos, by=list(anio=INSTAR_SN$anio), FUN=max, na.rm=TRUE)
names(max_huevos)[2] <- "max_huevos"
max_l1 <- aggregate(x = INSTAR_SN$l1, by=list(anio=INSTAR_SN$anio), FUN=max, na.rm=TRUE)
names(max_l1)[2] <- "max_l1"
max_l2 <- aggregate(x = INSTAR_SN$l2, by=list(anio=INSTAR_SN$anio), FUN=max, na.rm=TRUE)
names(max_l2)[2] <- "max_l2"
max_crisalidas <- aggregate(x = INSTAR_SN$crisalidas, by=list(anio=INSTAR_SN$anio), FUN=max, na.rm=TRUE)
names(max_crisalidas)[2] <- "max_crisalidas"
max_exergia <- aggregate(x = INSTAR_SN$exergia, by=list(anio=INSTAR_SN$anio), FUN=max, na.rm=TRUE)
names(max_exergia)[2] <- "max_exergia"

max_INSTAR <- cbind(max_huevos,max_l1, max_l2, max_crisalidas, max_exergia)
max_INSTAR <- max_INSTAR[ -c(3,5,7,9) ]
```

## Agregacion por minimo
La agregacion por minimo claramente subestima la poblacion, al menos en huevos, l1, l2 y crisalidas, ya que debido a la estacionalidad de cada fase se dan dias con valores 0, y por tanto el minimo es 0, no siendo este valor representativo de la poblacion ese anio. Si puede tener sentido para exergia, asi que la mantenemos:

```{r}
#min_huevos <- aggregate(x = INSTAR_SN$huevos, by=list(anio=INSTAR_SN$anio), FUN=min, na.rm=TRUE)
# names(min_huevos)[2] <- "min_huevos"
# min_l1 <- aggregate(x = INSTAR_SN$l1, by=list(anio=INSTAR_SN$anio), FUN=min, na.rm=TRUE)
# names(min_l1)[2] <- "min_l1"
# min_l2 <- aggregate(x = INSTAR_SN$l2, by=list(anio=INSTAR_SN$anio), FUN=min, na.rm=TRUE)
# names(min_l2)[2] <- "min_l2"
# min_crisalidas <- aggregate(x = INSTAR_SN$crisalidas, by=list(anio=INSTAR_SN$anio), FUN=min, na.rm=TRUE)
# names(min_crisalidas)[2] <- "min_crisalidas"
min_exergia <- aggregate(x = INSTAR_SN$exergia, by=list(anio=INSTAR_SN$anio), FUN=min, na.rm=TRUE)
names(min_exergia)[2] <- "min_exergia"

#min_INSTAR <- cbind(min_huevos,min_l1, min_l2, min_crisalidas, min_exergia)
min_INSTAR <- cbind(min_exergia)
#min_INSTAR <- min_INSTAR[ -c(3,5,7,9) ]
```

## Agregacion por media
La agregacion por media tiene el problema de que para dos anios con el mismo numero total de individuos, en un anio con el instar que sea (huevos, l1, l2 o crisalidas) muy repartidos a lo largo del tiempo, la media saldra menor que la de un anio con el mismo numero de individuos pero concentrados en un periodo mas corto de tiempo.

```{r}
mean_huevos <- aggregate(x = INSTAR_SN$huevos, by=list(anio=INSTAR_SN$anio), FUN=mean, na.rm=TRUE)
names(mean_huevos)[2] <- "mean_huevos"
mean_l1 <- aggregate(x = INSTAR_SN$l1, by=list(anio=INSTAR_SN$anio), FUN=mean, na.rm=TRUE)
names(mean_l1)[2] <- "mean_l1"
mean_l2 <- aggregate(x = INSTAR_SN$l2, by=list(anio=INSTAR_SN$anio), FUN=mean, na.rm=TRUE)
names(mean_l2)[2] <- "mean_l2"
mean_crisalidas <- aggregate(x = INSTAR_SN$crisalidas, by=list(anio=INSTAR_SN$anio), FUN=mean, na.rm=TRUE)
names(mean_crisalidas)[2] <- "mean_crisalidas"
mean_exergia <- aggregate(x = INSTAR_SN$exergia, by=list(anio=INSTAR_SN$anio), FUN=mean, na.rm=TRUE)
names(mean_exergia)[2] <- "mean_exergia"

mean_INSTAR <- cbind(mean_huevos, mean_l1, mean_l2, mean_crisalidas, mean_exergia)
mean_INSTAR <- mean_INSTAR[ -c(3,5,7,9) ]
```

## Exportacion de datos de agregacion
```{r}
# Creamos una tabla con todos los datos de agregacion y la exportamos

agreg_INSTAR_SN <- cbind(
  sum_huevos, max_huevos, mean_huevos, 
  sum_l1, max_l1, mean_l1,
  sum_l2, max_l2, mean_l2,
  sum_crisalidas, max_crisalidas,  mean_crisalidas,
  max_exergia, mean_exergia, min_exergia)
agreg_INSTAR_SN <- agreg_INSTAR_SN[ -c(3,5,7,9,11,13,15,17,19,21,23,25,27,29) ]

# write.csv(agreg_INSTAR_SN, "agreg_INSTAR_SN.csv", row.names=FALSE, na="")
```

*FIN FASE DE AGREGACION INSTAR*

# Validacion externa

Importacion de datos de agregacion INSTAR
```{r}
agreg_INSTAR_SN<-read.table("agreg_INSTAR_SN.csv", header=T, sep=",", dec=".")
```

Importacion de COPLAS y exploracion preliminar

**NOTA** la agregación de COPLAS se hizo en otro script y tiene que ser modificada
```{r}
COPLAS_SN_completo<-read.csv("cortijuela.csv", header=TRUE, dec =".", sep=",") # Sin agregar, datos brutos

boxplot(COPLAS_SN_completo$GRADO.REVISADO ~ COPLAS_SN_completo$RODAL)
plot(COPLAS_SN_completo$GRADO.REVISADO ~ COPLAS_SN_completo$fecha)

COPLAS_SN<-read.csv("coplas_cortijuela_prueba.csv", header=TRUE, dec =".", sep=",") # Medias para cada rodal (agregado)
```

- Es correcto hacer la media (al menos tal y como esta hecha) en una variable discreta como es COPLAS? 
    -> Entiendo que si, pero habra que usar la media obtenida, no el redondeo 
    -> Además lo adecuado sería ponderar según la superficie de cada rodal en el total (si tienen tamanios muy diferentes, al hacer la media se esta dando mas peso de la cuenta al pequenio y se esta subestimando el grande)

- En caso de que sea correcto, se debe/hay forma de considerar la varianza en la regresion?
- Debe considerarse COPLAS de alguna manera especial en la regresion por ser una variable discreta?

Por lo que veo habeis calculado una regresion lineal entre COPLAS e INSTAR, por que esperais una relacion lineal entre ambas variables? Lo ideal seria buscar la funcion que explica dicha relacion, y ver que tipo de funcion (lineal, logaritmica...) es, no? En cualquier caso, quizas lo mas esperable es una funcion logaritmica, como hace Cayuela (hace un glm, pero sobre datos en base logaritmica!). Intuitivamente, yo esperaria que para percibir cierta defoliacion es necesario un numero minimo de individuos, por debajo del cual no se observa defoliacion y a partir de cierta cantidad de individuos la defoliacion es maxima, dando igual si ese valor se sobrepasa por mucho o por poco (si todos los arboles estan defoliados da igual que haya X que X*10 individuos, por lo que ya no hay relacion lineal), por lo que yo esperaria una relacion exponencial.

Me preocupa que hay muchos datos 0 de COPLAS con valores muuuy diferentes de NetLogo... La agregacion juega un papel importante ahi, quizas al usar otra agregacion sale algo mejor (esperemos).

**Puesta en comun (29/08/2016)**

Asumimos que INSTAR(exergia) y COPLAS son la misma variable/miden lo mismo. Así, el modelo puede ser validado haciendo una regresión lineal (ver "Apuntes de validación de modelos"), donde COPLAS es la variable independiente (X) e INSTAR(exergia) es la variable independiente (Y). Con esto estamos asumiendo:

- Que, como se ha dicho antes, COPLAS e INSTAR miden lo mismo de la misma forma (en una relación inversa)
- Que se cumplen las asunciones de los modelos parametricos lineales (sobre Y y sobre los errores del modelo lineal), a saber:
  Normalidad: o, al menos, simetria
```{r}
hist(exergia$exergia) # todos los datos de energia
hist(mean_INSTAR$mean_exergia) # datos medios para cada anio
```
  No parecen normales... Ni siquiera simetricos :(
  El problema puede ser que el tamanio de la muestra es muy pequenio (n=14 en el agregado), aunque entonces el bruto no tendria por que tener el mismo problema.
  Posible solución: transformacion a una escala diferente (log o potencial)
  
  Homogeneidad de las varianzas: 
```{r}
var_exergia <- aggregate(x = INSTAR_SN$exergia, by=list(anio=INSTAR_SN$anio), FUN=var, na.rm=TRUE)
plot(var_exergia)
```
Habria que hacer un test para comprobar si son distintas significativamente, pero a simple vista no lo parece...

  Linealidad
```{r}
ds <- data.frame(cbind(mean_exergia,COPLAS_SN$INFE_AVG[(9:22)]))
names(ds)[3] <- "INFE_AVG"
plot(ds$mean_exergia ~ ds$INFE_AVG)
```
  ...
  
  Independencia: "the most common situation where this assumption is not met is when data are recorded in a time sequence"... Parece que tendremos que usar time series analysis si queremos algo decente...? Al menos con la agregacion tal y como se ha hecho hasta ahora.

De todas formas, aqui va la regresion:
```{r}
reg_exergia_COPLAS <- lm(ds$mean_exergia ~ ds$INFE_AVG)
abline(reg_exergia_COPLAS)
summary(reg_exergia_COPLAS)
plot(reg_exergia_COPLAS)
dev.off()
```

Ademas de la regresion COPLAS ~ INSTAR(exergia), se decide realizar tambien regresiones entre variables INSTAR relacionadas con el numero de larvas y los valores de COPLAS. En este caso, asumimos:
- Que el numero de dias equivalentes de larvas (en l1 y en l2) guarda una relacion respecto a COPLAS, siendo INSTAR(lx) la variable independiente, y COPLAS la dependiente (asumimos que defoliacion es consecuencia de densidad de poblacion). De manera que:
    a) la defoliacion aumenta muy rapidamente al principio segun aumenta el numero de dias equivalentes hasta llegar a cierta saturacion --> eso seria logaritmica
    b) la defoliacion aumenta lentamente al principio segun aumenta el numero de dias equivalentes --> eso seria exponencial
    c) a mayor numero de dias equivalentes mayor la defoliacion, considerando cierta fase estacionaria al principio y cierta saturacion en los valores mas altos --> eso no seria ninguna de las dos, en realidad. **Hay alguna funcion que nos lo explique adecuadamente?**
    
    Entiendo que asumimos b (funcion exponencial con INSTAR(lx) como variable independiente, y COPLAS como dependiente). Entonces:
    Asumimos: COPLAS = a*e^(b*INSTAR)
    Transformamos: Z = Ln(COPLAS)
    Modelo linealizado: Z = ln(a) + (b*INSTAR)
    
    Para estudir si el modelo logaritmo o exponencial explican/se adecuan a nuestros datos, lo mas facil es transformarlos a la funcion correspondiente, para asi realizar una regresion lineal entre los valores transformados y COPLAS. Entiendo que esto lo hacemos porque es mas facil de evaluar  un modelo lineal (con R2) que uno logaritmico o exponencial.
    
## Construccion de tabla de datos
```{r}
log_COPLAS <- data.frame(log(ds[3]))
ds2 <- cbind(sum_l1, sum_l2, log_COPLAS)
ds2 <- ds2[ -c(3) ]
names(ds2)[4] <- "log_COPLAS"
```

## Regresion

NO SE HAN COMPROBADO LAS ASUNCIONES

```{r}
reg_l1_COPLAS <- lm(ds2$log_COPLAS~ds2$sum_l1)
```

  El problema es que la transformacion da valores "-Inf"... 
  Posible solucion: "Use log(Z+c) where c is an appropiate constant if there are zeros in the data set because you can't take the log of zero. Some people use the smallest possible value for their variable as a constant, others use an arbitrarily small number, such as 0.001". Careful with ANOVA significancies if this solution is applied!

```{r}
ds2$log_COPLAS[ds2$log_COPLAS == "-Inf"] <- "-0.001"
reg_l1_COPLAS <- lm(ds2$log_COPLAS~ds2$sum_l1)
summary(reg_l1_COPLAS)
plot(reg_l1_COPLAS)
dev.off()
```


~~## Transformacion log de datos INSTAR~~
~~log_agreg_INSTAR_SN<- data.frame(
  "anio" = agreg_INSTAR_SN$anio,
  log_sum_huevos = (log(agreg_INSTAR_SN$sum_huevos)),
  log_max_huevos = (log(agreg_INSTAR_SN$max_huevos)),
  log_mean_huevos = (log(agreg_INSTAR_SN$mean_huevos)),
  log_sum_l1 = (log(agreg_INSTAR_SN$sum_l1)),
  log_max_l1 = (log(agreg_INSTAR_SN$max_l1)),
  log_mean_l1 = (log(agreg_INSTAR_SN$mean_l1)),
  log_sum_l2 = (log(agreg_INSTAR_SN$sum_l2)),
  log_max_l2 = (log(agreg_INSTAR_SN$max_l2)),
  log_mean_l2 = (log(agreg_INSTAR_SN$mean_l2)),
  log_sum_crisalidas = (log(agreg_INSTAR_SN$sum_crisalidas)),
  log_max_crisalidas = (log(agreg_INSTAR_SN$max_crisalidas)),
  log_mean_crisalidas = (log(agreg_INSTAR_SN$mean_crisalidas)),
  log_max_exergia = (log(agreg_INSTAR_SN$max_exergia)),
  log_mean_exergia = (log(agreg_INSTAR_SN$mean_exergia)),
  log_min_exergia = (log(agreg_INSTAR_SN$min_exergia)))~~

~~## Correlaciones y regresiones
**La variable independiente (x) son los datos de COPLAS, y la variable dependiente (y) son los datos de Instar:**
INSTAR = a·COPLAS + b (INSTAR "described by" COPLAS)~~

- Se cumplen las asunciones de una regresion? (normalidad,...) -> Usamos un glm, ya que lm asume que el error de los datos sigue una distribucion normal, mientras que el glm asume que otras distribuciones son posibles.
- lm o glm? (ver anterior) Hago el lm tambien para ver los R2
- cor y/o lm/glm? ejemplo de cor: cor(tabla_regresion$log_sum_l1, tabla_regresion$INFE_AVG)

~~# Construccion de tabla~~
~~tabla_regresion <- cbind(log_agreg_INSTAR_SN, COPLAS_SN[-c((1:8), 23), -c(1,4)])~~

~~# Regresiones glm y resultados~~
~~reg1_glm  <- glm(tabla_regresion$log_sum_huevos ~ tabla_regresion$INFE_AVG)~~
~~reg2_glm  <- glm(tabla_regresion$log_max_huevos ~ tabla_regresion$INFE_AVG)~~
~~reg3_glm  <- glm(tabla_regresion$log_mean_huevos ~ tabla_regresion$INFE_AVG)~~
~~reg4_glm  <- glm(tabla_regresion$log_sum_l1 ~ tabla_regresion$INFE_AVG)~~
~~reg5_glm  <- glm(tabla_regresion$log_max_l1 ~ tabla_regresion$INFE_AVG)~~
~~reg6_glm  <- glm(tabla_regresion$log_mean_l1 ~ tabla_regresion$INFE_AVG)~~
~~reg7_glm  <- glm(tabla_regresion$log_sum_l2 ~ tabla_regresion$INFE_AVG)~~
~~reg8_glm  <- glm(tabla_regresion$log_max_l2 ~ tabla_regresion$INFE_AVG)~~
~~reg9_glm  <- glm(tabla_regresion$log_mean_l2 ~ tabla_regresion$INFE_AVG)~~
~~reg10_glm <- glm(tabla_regresion$log_sum_crisalidas ~ tabla_regresion$INFE_AVG)~~
~~reg11_glm <- glm(tabla_regresion$log_max_crisalidas ~ tabla_regresion$INFE_AVG)~~
~~reg12_glm <- glm(tabla_regresion$log_mean_crisalidas ~ tabla_regresion$INFE_AVG)~~
~~reg13_glm <- glm(tabla_regresion$log_max_exergia ~ tabla_regresion$INFE_AVG)~~
~~reg14_glm <- glm(tabla_regresion$log_mean_exergia ~ tabla_regresion$INFE_AVG)~~
~~reg15_glm <- glm(tabla_regresion$log_min_exergia ~ tabla_regresion$INFE_AVG)~~

~~# Regresiones glm y resultados~~
~~reg1_lm  <- lm(tabla_regresion$log_sum_huevos ~ tabla_regresion$INFE_AVG)~~
~~reg2_lm  <- lm(tabla_regresion$log_max_huevos ~ tabla_regresion$INFE_AVG)~~
~~reg3_lm  <- lm(tabla_regresion$log_mean_huevos ~ tabla_regresion$INFE_AVG)~~
~~reg4_lm  <- lm(tabla_regresion$log_sum_l1 ~ tabla_regresion$INFE_AVG)~~
~~reg5_lm  <- lm(tabla_regresion$log_max_l1 ~ tabla_regresion$INFE_AVG)~~
~~reg6_lm  <- lm(tabla_regresion$log_mean_l1 ~ tabla_regresion$INFE_AVG)~~
~~reg7_lm  <- lm(tabla_regresion$log_sum_l2 ~ tabla_regresion$INFE_AVG)~~
~~reg8_lm  <- lm(tabla_regresion$log_max_l2 ~ tabla_regresion$INFE_AVG)~~
~~reg9_lm  <- lm(tabla_regresion$log_mean_l2 ~ tabla_regresion$INFE_AVG)~~
~~reg10_lm <- lm(tabla_regresion$log_sum_crisalidas ~ tabla_regresion$INFE_AVG)~~
~~reg11_lm <- lm(tabla_regresion$log_max_crisalidas ~ tabla_regresion$INFE_AVG)~~
~~reg12_lm <- lm(tabla_regresion$log_mean_crisalidas ~ tabla_regresion$INFE_AVG)~~
~~reg13_lm <- lm(tabla_regresion$log_max_exergia ~ tabla_regresion$INFE_AVG)~~
~~reg14_lm <- lm(tabla_regresion$log_mean_exergia ~ tabla_regresion$INFE_AVG)~~
~~reg15_lm <- lm(tabla_regresion$log_min_exergia ~ tabla_regresion$INFE_AVG)~~

# Exploracion grafica (ejemplo)
```{r}
plot(tabla_regresion$log_sum_huevos ~ tabla_regresion$INFE_AVG)
abline(lm(tabla_regresion$log_sum_huevos ~ tabla_regresion$INFE_AVG))
```

# Regresion multiple:

No entiendo esto... Si l2 viene de l1, al hacer una regresion multiple l1+l2 (o huevos+l1, o cualquier combinacion de variables de densidad de poblacion), no se esta metiendo una redundancia? Sin embargo, si me parece que podria ser interesante hacer una regresion multiple considerando una variable de densidad de poblacion y una relacionada con las condiciones climaticas (tmin, tmax y/o tmedia), ya que se podria esperar que, por ejemplo, huevos+tmin sea un buen predictor de COPLAS, no?

# Series temporales  

~~No se muy bien cual es el objetivo de el analisis de series temporales, por lo que quizas lo que digo no tiene sentido, corregidme plis :)~~

~~Segun lo entiendo, queremos hacer un analisis de series temporales comparando COPLAS e INSTAR, ya que al ser variables que cambian en el tiempo debido a varios factores (condiciones de cada anio, estacionalidad, variabilidad,...) su analisis basado en regresion es limitado.~~

~~En tal caso, creo que es una pena usar datos agregados de INSTAR (perdiendo resolucion) cuando precisamente el analisis como serie temporal nos mostraria la estacionalidad, la tendencia, etc. Por tanto, yo usaria los datos brutos de INSTAR. Ahora, hay un problema, y es que la funcion ts no se lleva bien con los anios bisiestos, ya que la frecuencia tiene que ser un valor fijo para toda la serie (que no para dos series, por lo que no es un problema comparar COPLAS e INSTAR aunque tengan distinta frecuencia). En los foros proponen usar zoo para evitar este problema, que es lo que usamos en Ecoinformqtica, creo... Otra opcion seria eliminar de los datos de INSTAR el 29 de febrero de los anios bisiestos (filas 980, 2441, 3902), aunque parece una solucion poco elegante...~~

~~En cuanto al error que te sale en el codigo, entiendo que es porque cuando la frecuencia es 1, decompose no funciona ya que no se puede observar estacionalidad si hay una sola medida por anio. Por eso cambiando a freq=2 se elimina el error, pero no es correcto ya que nosotros solo tenemos una medida/anio. Por tanto, yo entiendo que no se puede aplicar la funcion decompose sobre COPLAS, sino que habra que buscar otras herramientas para evaluar tendencias. En cualquier caso, y despues de hablar con Antonio, yo entiendo que lo que habria que hacer es coger los datos de INSTAR, analizarlos (en bruto) como serie temporal, buscando estacionalidad, tendencias, ruido, etc. y quizas comparar esta serie con una serie climatica (tmin, tmax y/o tmedia), de esta manera demostrando que los resultados del modelo guardan relacion con las condiciones climaticas, como se espera del codigo. Si ademas encontramos la forma de analizar series temporales de frecuencia 1 entonces podriamos comparar COPLAS e INSTAR.~~

Queremos:

- *Cuantificar el grado de ajuste entre los datos de INSTAR y COPLAS*

Problemas metodologicos:
- COPLAS e INSTAR no tienen la misma frecuencia
- INSTAR contienen datos diarios, considerando años bisiestos
- COPLAS tiene anios sin datos (1994 y 1997)

Analisis a realizar:
- Comparar COPLAS e INSTARagregado: esta opcion debe excluir el analisis de la estacionalidad de los datos, ya que al agregarse a un valor/anio no se podra observar la estacionalidad. Se podra, por tanto, analizar si la tendencia y el ruido son similares. Para esto asumimos que estas series tienen la forma:

x(t) = m(t) + z(t)

**DUDA** no seria este el mismo analisis que la regresion? este parece mas adecuado porque considera cada dato dentro de la serie, y puede afinar mas ya que se estudian tambien las correlaciones entre cada anio, pero en realidad en el mismo (lm o glm COPLAS vs INSTAR)  

- Validacion interna del modelo: analisis de la serie temporal de INSTAR y su relacion con las variables climaticas (temperatura). De esta manera, se podran observar la variabilidad estacional de la serie, y compararla con los patrones meteorologicos. Esto requiere solucionar el problema de los anios bisiestos. Opciones: eliminar los datos de los 29 de febrero, agregacion mensual de los datos, usar otros paquetes que consideren series de datos de frecuencia irregular (zoo?), ...?

## COPLAS vs INSTARagregado

```{r}
COPLAS_SN_ts <-ts(COPLAS_SN[2], start=1993, end=2015, frequency=1)
plot(COPLAS_SN_ts)
decompose(COPLAS_SN_ts) # No se puede hacer porque tiene freq=1 (no puede medir estacionalidad) :(

acf(COPLAS_SN_ts, na.action =na.pass) # By default, no missing values are allowed. If the na.action function passes through missing values (as na.pass does), the covariances are computed from the complete cases. This means that the estimate computed may well not be a valid autocorrelation sequence, and may contain missing values.
```

Asumimos una relacion exponencial entre COPLAS e INSTAR (no estoy muy segura de esto...):

INSTAR = (a*e)^(b*COPLAS)

Por tanto usamos los datos de INSTAR transformados y probamos con los dias equivalentes de l2: 

```{r}
x <- log_agreg_INSTAR_SN$log_sum_l2

log_INSTAR_ts <-ts(x, start=2001, end=2014, frequency=1)
plot(log_INSTAR_ts)
acf(log_INSTAR_ts)
```

Comparamos COPLAS e INSTARagreg
```{r}
plot(ts.intersect(log_INSTAR_ts,COPLAS_SN_ts))
plot(as.vector(log_INSTAR_ts), as.vector(COPLAS_SN_ts[9:22,]))
lm_l2 <- lm(as.vector(log_INSTAR_ts)~ as.vector(COPLAS_SN_ts[9:22,]))

summary(lm_l2)
plot(lm_l2)

# METER EL dev.off para dividir el espacio!
```

Creo que esto seria lo mismo, solo que con otra sintaxis
```{r}
intersect <- data.frame(ts.intersect(log_INSTAR_ts,COPLAS_SN_ts))
lm_l2 <- lm(intersect$log_INSTAR_ts~intersect$COPLAS_SN_ts)
```

Bastante mala relación....


plot(as.vector(log_INSTAR_ts), as.vector(COPLAS_SN_ts[9:22,]))
cor(log_INSTAR_ts, COPLAS_SN_ts[9:22,])

## Analisis de INSTARbruto (Con "ts", eliminando 29 de febrero)

INSTAR:
```{r}
INSTAR_SN_sinbisestos <- INSTAR_SN[-c(980,2441,3902),]
# INSTAR_SN_ts <- ts(INSTAR_SN_sinbisestos[2:6], start=c(2001,176), end=c(2014,161), freq=365) # Definimos como ts todo el conjunto de datos 
INSTAR_SN_ts_huevos <- ts(INSTAR_SN_sinbisestos[2], start=c(2001,176), end=c(2014,161), freq=365) # Definimos como ts cada variable por separado
plot(INSTAR_SN_ts_huevos)
plot(decompose(INSTAR_SN_ts_huevos, type = c("additive")))
plot(decompose(INSTAR_SN_ts_huevos, type = c("multiplicative")))

ts.intersect(INSTAR_SN_ts_huevos,COPLAS_SN_ts) # No se puede hacer si no tienen la misma frecuencia... :(
```

> "If the seasonal effect tends to increase as the trend increases, a multiplicative model may be more appropriate"- --> Quizás multiplicative es más correcto en nuestro caso? Ver página 20 en "Introductory Time Series with R":
"In this example, the multiplicative model would seem more appropriate than the additive model because the variance of the original series and trend increase with time (Fig. 1.14). However, the random component, which corresponds to zt, also has an increasing variance, which indicates that a logtransformation (Equation (1.4)) may be more appropriate for this series (Fig. 1.14)."

Análisis exploratorio:
```{r}
aggregate(INSTAR_SN_ts_huevos)
plot(aggregate(INSTAR_SN_ts_huevos))
acf(INSTAR_SN_ts_huevos)


plot(decompose(INSTAR_SN_ts_huevos, type ="mult"))
# o lo mismo:
# huevos.decom <- decompose(INSTAR_SN_ts_huevos, type ="mult") 
# plot(huevos.decom)
trend <- huevos.decom$trend
seasonal <- huevos.decom$seasonal
random <- huevos.decom$random

ts.plot(cbind(trend,trend*seasonal, trend*random),col=c("black", "red", "blue"), main="cbind(trend,trend*seasonal, trend*random") 
legend("topright",legend=c("trend","trend*seasonal", "trend*random"), text.col=c("black","red", "blue"), col=c("black","red", "blue"))
```
**NOTAS**
start = 176 porque el 25 de junio de un anio no bisiesto es el dia 176 del anio
end = 161 porque el 10 de junio de un anio no bisiesto es el dia 161 del anio

## Datos de temperatura 
```{r}
temp_sn<-read.csv("temp_sn.csv", header=TRUE, dec =".", sep=",")
temp_sn_sinbisestos <- temp_sn[-c(980,2441,3902),]

tmax_sn_ts <- ts(temp_sn_sinbisestos[2], start=c(2001,176), end=c(2014,161), freq=365)
tmax_decom <- decompose(tmax_sn_ts)

tmin_sn_ts <- ts(temp_sn_sinbisestos[3], start=c(2001,176), end=c(2014,161), freq=365)
tmin_decom <- decompose(tmin_sn_ts)

tmedia_sn_ts <- ts(temp_sn_sinbisestos[4], start=c(2001,176), end=c(2014,161), freq=365)
tmedia_decom <- decompose(tmedia_sn_ts)

plot(cbind(tmax_decom$trend, tmin_decom$trend,tmedia_decom$trend))
plot(cbind(tmax_decom$seasonal, tmin_decom$seasonal,tmedia_decom$seasonal))
plot(cbind(tmax_decom$random, tmin_decom$random,tmedia_decom$random))
```

## Temperatura vs INSTAR
```{r}
plot(cbind(INSTAR_SN_ts_huevos, tmax_sn_ts, tmin_sn_ts, tmedia_sn_ts), main="Huevos & temperatures")
dev.off()

```


> plot(decompose(Elec.ts))
> Elec.decom <- decompose(Elec.ts, type = "mult")
> plot(Elec.decom)
> Trend <- Elec.decom$trend
> Seasonal <- Elec.decom$seasonal
> ts.plot(cbind(Trend, Trend * Seasonal), lty = 1:2)


# Pruebas de plots:

ts.plot(INSTAR_SN_ts_huevos, tmax_sn_ts, tmin_sn_ts, tmedia_sn_ts, col=c("black", "red", "blue", "orange"))

ts.plot(INSTAR_SN_ts_huevos, axes=FALSE, ylim=c(0,1500000), ylab="huevos")
par(new=TRUE) # Allow a second plot on the same graph

ts.plot(tmax_sn_ts, tmin_sn_ts, tmedia_sn_ts, pch=15, col=c("red", "blue", "orange"), ylab="temperature", ylim=c(0,30), axes=FALSE) # Plot the second plot

legend("topright",legend=c("huevos","tmax", "tmin", "tmedia"), text.col=c("black","red", "blue", "orange"), col=c("black","red", "blue", "orange")) # Add Legend

ts.plot(cbind(trend,trend*seasonal, trend*random),lty=1:2) # lty 
gives different line types,

# Pruebas (basado en el reto final de ecoinformatica)
```{r}
## Exploratory plot
plot(INSTAR_SN$fecha, INSTAR_SN$huevos, type='o', 
      xlab='year', pch=19, col='#325B84',
      ylab='huevos', ylim=c(0,1500000))

## Trend analysis

library('Kendall') 
m <- MannKendall(INSTAR_SN$huevos)
m

# Considera la serie como valores puntuales (no medidas diarias) por lo que no encuentra tendencia ya que sube y baja en cada anio (tiene estacionalidad)

### Test a linear regression
ml <- lm(INSTAR_SN$fecha~INSTAR_SN$huevos)
summary(ml) # ERROR: no sabe hacer un lm sobre una fecha

huevos_zoo <- zoo(INSTAR_SN$fecha~INSTAR_SN$huevos)

#Definimos la tabla como serie temporal - cada fila es una serie
str(huevos_zoo)
View(huevos_zoo)

huevos_theil <- mannKen(as.ts(huevos_zoo)) #Ejecutamos el test
View(nieve_theil)
nieve_theil<-as.data.frame(nieve_theil)
```